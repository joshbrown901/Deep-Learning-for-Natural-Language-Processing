{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8374085,"sourceType":"datasetVersion","datasetId":4978785},{"sourceId":8379332,"sourceType":"datasetVersion","datasetId":4982779},{"sourceId":8384322,"sourceType":"datasetVersion","datasetId":4986441},{"sourceId":8384327,"sourceType":"datasetVersion","datasetId":4986446},{"sourceId":8389956,"sourceType":"datasetVersion","datasetId":4990369}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers sentencepiece sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-12T06:31:42.884803Z","iopub.execute_input":"2024-05-12T06:31:42.885186Z","iopub.status.idle":"2024-05-12T06:31:56.991972Z","shell.execute_reply.started":"2024-05-12T06:31:42.885140Z","shell.execute_reply":"2024-05-12T06:31:56.990836Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-2.8.2 sacrebleu-2.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:31:56.993942Z","iopub.execute_input":"2024-05-12T06:31:56.994243Z","iopub.status.idle":"2024-05-12T06:32:10.042719Z","shell.execute_reply.started":"2024-05-12T06:31:56.994216Z","shell.execute_reply":"2024-05-12T06:32:10.041748Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nCollecting accelerate\n  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.29.3\n    Uninstalling accelerate-0.29.3:\n      Successfully uninstalled accelerate-0.29.3\nSuccessfully installed accelerate-0.30.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom tqdm.auto import tqdm\n\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom typing import List, Union, Tuple, Dict\nfrom datasets import load_dataset\nimport json\nimport logging\n\nfrom transformers import (\n    BartForConditionalGeneration,\n    BartTokenizer,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    T5ForConditionalGeneration,\n    T5Tokenizer,\n    \n    M2M100ForConditionalGeneration,\n    NllbTokenizerFast,\n    BartTokenizerFast,\n    T5TokenizerFast,\n    BartForConditionalGeneration,\n    PreTrainedTokenizerFast,\n    PreTrainedModel,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:32:10.047346Z","iopub.execute_input":"2024-05-12T06:32:10.047645Z","iopub.status.idle":"2024-05-12T06:32:27.879168Z","shell.execute_reply.started":"2024-05-12T06:32:10.047615Z","shell.execute_reply":"2024-05-12T06:32:27.878297Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-12 06:32:19.561331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-12 06:32:19.561431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-12 06:32:19.698459: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training datasets preparation:","metadata":{}},{"cell_type":"code","source":"en_paradetox_content = load_dataset(\"s-nlp/en_paradetox_content\")\nparadetox = load_dataset(\"s-nlp/paradetox\")\nparanmt_for_detox = load_dataset(\"s-nlp/paranmt_for_detox\")\nmultilingual_paradetox = load_dataset(\"textdetox/multilingual_paradetox\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:34:25.994819Z","iopub.execute_input":"2024-05-12T06:34:25.995624Z","iopub.status.idle":"2024-05-12T06:35:16.207556Z","shell.execute_reply.started":"2024-05-12T06:34:25.995593Z","shell.execute_reply":"2024-05-12T06:35:16.206379Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6035686f16e2447c8c060e40e8cf654a"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 3.53M/3.53M [00:01<00:00, 2.46MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0410eb16b76493fa14ddb91c43e0ed0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ccb4869ad54a328361ef6ef85b0471"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 2.04M/2.04M [00:01<00:00, 1.63MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc687c1067ad4c29b6afd5189f4a2a19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f63482588f2a47368cc3fe5904e7c370"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 139k/139k [00:00<00:00, 221kB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d407f34f8394b8588bd969e9dffaa30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc69a45189c94551bad65ffbdbdb269c"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 35.8k/35.8k [00:00<00:00, 68.5kB/s]\nDownloading data: 100%|██████████| 53.8k/53.8k [00:00<00:00, 112kB/s]\nDownloading data: 100%|██████████| 49.4k/49.4k [00:00<00:00, 81.6kB/s]\nDownloading data: 100%|██████████| 63.7k/63.7k [00:00<00:00, 133kB/s]\nDownloading data: 100%|██████████| 44.8k/44.8k [00:00<00:00, 78.8kB/s]\nDownloading data: 100%|██████████| 78.0k/78.0k [00:00<00:00, 161kB/s]\nDownloading data: 100%|██████████| 60.1k/60.1k [00:00<00:00, 124kB/s]\nDownloading data: 100%|██████████| 53.9k/53.9k [00:00<00:00, 110kB/s]\nDownloading data: 100%|██████████| 49.8k/49.8k [00:00<00:00, 106kB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating en split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f03d331eaf4a93bfb909ada8ace809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating ru split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b378e5003a814cd7a510315f527622f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating uk split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64e174d8a6e549f1bfc6b7e345b24f9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating de split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f0b5ee6651b49448ed54e9a82efa5a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating es split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b24562b8f3742719b527ea2f7e8a2e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating am split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da981e1a676143ad83dbd7bcb7ad5336"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating zh split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b3c3702ebbc48bfae90678435404f87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating ar split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b99e8e0eae9d4803b40b616fc1d34310"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating hi split:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eda6116ab58046868da9211696533352"}},"metadata":{}}]},{"cell_type":"code","source":"# Concatinating train and validation parts of the first dataset:\n\nen_paradetox_content = pd.DataFrame(en_paradetox_content[\"train\"])\nparadetox_df = pd.DataFrame(paradetox[\"train\"])\nparanmt_for_detox_df = pd.DataFrame(paranmt_for_detox[\"train\"])\neng_multilingual_paradetox_df = pd.DataFrame(multilingual_paradetox[\"en\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:16.209625Z","iopub.execute_input":"2024-05-12T06:35:16.210011Z","iopub.status.idle":"2024-05-12T06:35:18.526111Z","shell.execute_reply.started":"2024-05-12T06:35:16.209957Z","shell.execute_reply":"2024-05-12T06:35:18.525293Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"en_paradetox_content = en_paradetox_content.drop(en_paradetox_content[en_paradetox_content[\"match\"] == False].index)\nen_paradetox_content = en_paradetox_content.drop(\"match\", axis=1)\n\ncolumns_titles = [\"toxic\",\"neutral\"]\nen_paradetox_content = en_paradetox_content.reindex(columns=columns_titles)\n\nen_paradetox_content = en_paradetox_content.reset_index(drop=True)\nen_paradetox_content = en_paradetox_content.rename(columns={\"toxic\": \"toxic_sentence\", \"neutral\": \"neutral_sentence\"})\n\nen_paradetox_content.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.527221Z","iopub.execute_input":"2024-05-12T06:35:18.527502Z","iopub.status.idle":"2024-05-12T06:35:18.557889Z","shell.execute_reply.started":"2024-05-12T06:35:18.527479Z","shell.execute_reply":"2024-05-12T06:35:18.557005Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                      toxic_sentence  \\\n0  so sad the voters in her district are stupid e...   \n1                  trump is a liar and a psychotic .   \n2  professors who sit in stinky old buildings dre...   \n\n                                    neutral_sentence  \n0  so sad the voters in her district are stupid e...  \n1      Trump is indifferent and not into his senses.  \n2  professors who sit in an old buildings dreamin...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>so sad the voters in her district are stupid e...</td>\n      <td>so sad the voters in her district are stupid e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trump is a liar and a psychotic .</td>\n      <td>Trump is indifferent and not into his senses.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>professors who sit in stinky old buildings dre...</td>\n      <td>professors who sit in an old buildings dreamin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"paradetox_df = paradetox_df.rename(columns={\"en_toxic_comment\": \"toxic_sentence\", \"en_neutral_comment\": \"neutral_sentence\"})\nparadetox_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.559940Z","iopub.execute_input":"2024-05-12T06:35:18.560259Z","iopub.status.idle":"2024-05-12T06:35:18.570346Z","shell.execute_reply.started":"2024-05-12T06:35:18.560235Z","shell.execute_reply":"2024-05-12T06:35:18.569475Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                      toxic_sentence  \\\n0                           he had steel balls too !   \n1  dude should have been taken to api , he would ...   \n2  im not gonna sell the fucking picture , i just...   \n\n                                    neutral_sentence  \n0                                  he was brave too!  \n1  It would have been good if he went to api. He ...  \n2  I'm not gonna sell the picture, i just want to...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>he had steel balls too !</td>\n      <td>he was brave too!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dude should have been taken to api , he would ...</td>\n      <td>It would have been good if he went to api. He ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im not gonna sell the fucking picture , i just...</td>\n      <td>I'm not gonna sell the picture, i just want to...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"paranmt_for_detox_df = paranmt_for_detox_df.rename(columns={\"toxic_comment\": \"toxic_sentence\", \"neutral_comment\": \"neutral_sentence\"})\nparanmt_for_detox_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.571628Z","iopub.execute_input":"2024-05-12T06:35:18.571925Z","iopub.status.idle":"2024-05-12T06:35:18.585178Z","shell.execute_reply.started":"2024-05-12T06:35:18.571901Z","shell.execute_reply":"2024-05-12T06:35:18.584237Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                      toxic_sentence  \\\n0                                       Shut it off!   \n1                               Damned strange ones.   \n2  Come on. I know I was a bit of a jerk back in ...   \n\n                                    neutral_sentence  \n0                                       turn it off!  \n1                                      pretty weird.  \n2  I know I was quite a bastard then, but I've gr...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Shut it off!</td>\n      <td>turn it off!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Damned strange ones.</td>\n      <td>pretty weird.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Come on. I know I was a bit of a jerk back in ...</td>\n      <td>I know I was quite a bastard then, but I've gr...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eng_multilingual_paradetox_df = eng_multilingual_paradetox_df.rename(columns={\"toxic_sentence\": \"toxic_sentence\", \"neutral_sentence\": \"neutral_sentence\"})\neng_multilingual_paradetox_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.586327Z","iopub.execute_input":"2024-05-12T06:35:18.586587Z","iopub.status.idle":"2024-05-12T06:35:18.599360Z","shell.execute_reply.started":"2024-05-12T06:35:18.586566Z","shell.execute_reply":"2024-05-12T06:35:18.598345Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                      toxic_sentence  \\\n0  then all of a sudden i see her , shes now got ...   \n1  My page should be protected first so that wort...   \n2                        You made a mistake you ass.   \n\n                                    neutral_sentence  \n0    All of a sudden i see her, she is all grown up.  \n1  My page should be protected first so that unpl...  \n2                                You made a mistake.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>then all of a sudden i see her , shes now got ...</td>\n      <td>All of a sudden i see her, she is all grown up.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My page should be protected first so that wort...</td>\n      <td>My page should be protected first so that unpl...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You made a mistake you ass.</td>\n      <td>You made a mistake.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eng_df = pd.concat([en_paradetox_content, paradetox_df, paranmt_for_detox_df, eng_multilingual_paradetox_df], axis=0)\neng_df","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.600617Z","iopub.execute_input":"2024-05-12T06:35:18.600902Z","iopub.status.idle":"2024-05-12T06:35:18.616101Z","shell.execute_reply.started":"2024-05-12T06:35:18.600880Z","shell.execute_reply":"2024-05-12T06:35:18.615246Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                        toxic_sentence  \\\n0    so sad the voters in her district are stupid e...   \n1                    trump is a liar and a psychotic .   \n2    professors who sit in stinky old buildings dre...   \n3    i hope i live long enough to see at least thes...   \n4    unkind , uncharitable , mean , small minded , ...   \n..                                                 ...   \n395  at least one party gives a crap about humans a...   \n396                        parliament is a lame duck .   \n397  side - note , why the fuck does everything the...   \n398       You're not being helpful, either, tiny-dick.   \n399  Prove my comment wrong and post a video of how...   \n\n                                      neutral_sentence  \n0    so sad the voters in her district are stupid e...  \n1        Trump is indifferent and not into his senses.  \n2    professors who sit in an old buildings dreamin...  \n3    i hope i live long enough to see at least thes...  \n4                Unkind, uncharitable, mean, unlearned  \n..                                                 ...  \n395  at leas one party pays attention about humans ...  \n396                                 Parliament is dull  \n397  side-note , why does everything the us make ha...  \n398                  You're not being helpful, either.  \n399  Prove my comment wrong and post a video of how...  \n\n[49292 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>so sad the voters in her district are stupid e...</td>\n      <td>so sad the voters in her district are stupid e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trump is a liar and a psychotic .</td>\n      <td>Trump is indifferent and not into his senses.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>professors who sit in stinky old buildings dre...</td>\n      <td>professors who sit in an old buildings dreamin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i hope i live long enough to see at least thes...</td>\n      <td>i hope i live long enough to see at least thes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>unkind , uncharitable , mean , small minded , ...</td>\n      <td>Unkind, uncharitable, mean, unlearned</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>at least one party gives a crap about humans a...</td>\n      <td>at leas one party pays attention about humans ...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>parliament is a lame duck .</td>\n      <td>Parliament is dull</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>side - note , why the fuck does everything the...</td>\n      <td>side-note , why does everything the us make ha...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>You're not being helpful, either, tiny-dick.</td>\n      <td>You're not being helpful, either.</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>Prove my comment wrong and post a video of how...</td>\n      <td>Prove my comment wrong and post a video of how...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49292 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eng_df[\"lang\"] = \"en\"\neng_df = eng_df.reset_index(drop=True)\neng_df","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.617724Z","iopub.execute_input":"2024-05-12T06:35:18.617967Z","iopub.status.idle":"2024-05-12T06:35:18.637709Z","shell.execute_reply.started":"2024-05-12T06:35:18.617947Z","shell.execute_reply":"2024-05-12T06:35:18.636802Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                          toxic_sentence  \\\n0      so sad the voters in her district are stupid e...   \n1                      trump is a liar and a psychotic .   \n2      professors who sit in stinky old buildings dre...   \n3      i hope i live long enough to see at least thes...   \n4      unkind , uncharitable , mean , small minded , ...   \n...                                                  ...   \n49287  at least one party gives a crap about humans a...   \n49288                        parliament is a lame duck .   \n49289  side - note , why the fuck does everything the...   \n49290       You're not being helpful, either, tiny-dick.   \n49291  Prove my comment wrong and post a video of how...   \n\n                                        neutral_sentence lang  \n0      so sad the voters in her district are stupid e...   en  \n1          Trump is indifferent and not into his senses.   en  \n2      professors who sit in an old buildings dreamin...   en  \n3      i hope i live long enough to see at least thes...   en  \n4                  Unkind, uncharitable, mean, unlearned   en  \n...                                                  ...  ...  \n49287  at leas one party pays attention about humans ...   en  \n49288                                 Parliament is dull   en  \n49289  side-note , why does everything the us make ha...   en  \n49290                  You're not being helpful, either.   en  \n49291  Prove my comment wrong and post a video of how...   en  \n\n[49292 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>so sad the voters in her district are stupid e...</td>\n      <td>so sad the voters in her district are stupid e...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trump is a liar and a psychotic .</td>\n      <td>Trump is indifferent and not into his senses.</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>professors who sit in stinky old buildings dre...</td>\n      <td>professors who sit in an old buildings dreamin...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i hope i live long enough to see at least thes...</td>\n      <td>i hope i live long enough to see at least thes...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>unkind , uncharitable , mean , small minded , ...</td>\n      <td>Unkind, uncharitable, mean, unlearned</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49287</th>\n      <td>at least one party gives a crap about humans a...</td>\n      <td>at leas one party pays attention about humans ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>49288</th>\n      <td>parliament is a lame duck .</td>\n      <td>Parliament is dull</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>49289</th>\n      <td>side - note , why the fuck does everything the...</td>\n      <td>side-note , why does everything the us make ha...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>49290</th>\n      <td>You're not being helpful, either, tiny-dick.</td>\n      <td>You're not being helpful, either.</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>49291</th>\n      <td>Prove my comment wrong and post a video of how...</td>\n      <td>Prove my comment wrong and post a video of how...</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>49292 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Trainig the model on the English corpus","metadata":{}},{"cell_type":"code","source":"lang_id_mapping = {\n        \"ru\": \"rus_Cyrl\",\n        \"en\": \"eng_Latn\",\n        \"am\": \"amh_Ethi\",\n        \"es\": \"spa_Latn\",\n        \"uk\": \"ukr_Cyrl\",\n        \"zh\": \"zho_Hans\",\n        \"ar\": \"arb_Arab\",\n        \"hi\": \"hin_Deva\",\n        \"de\": \"deu_Latn\",\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.638907Z","iopub.execute_input":"2024-05-12T06:35:18.639259Z","iopub.status.idle":"2024-05-12T06:35:18.644162Z","shell.execute_reply.started":"2024-05-12T06:35:18.639230Z","shell.execute_reply":"2024-05-12T06:35:18.643242Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display\n\nclass DetoxDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, data, tokenizer, lang):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.tokenizer.src_lang = lang_id_mapping[lang]\n        self.tokenizer.tgt_lang = lang_id_mapping[\"en\"]\n\n    def __getitem__(self, idx):\n\n        source = self.tokenizer(\n            self.data.iloc[idx].toxic_sentence,\n            max_length=150,\n            pad_to_max_length=True,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        target = self.tokenizer(\n            self.data.iloc[idx].neutral_sentence,\n            max_length=150,\n            pad_to_max_length=True,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n        source[\"labels\"] = target[\"input_ids\"]\n\n        return {k: v.squeeze(0) for k, v in source.items()}\n\n    def __len__(self):\n        return self.data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.647905Z","iopub.execute_input":"2024-05-12T06:35:18.648456Z","iopub.status.idle":"2024-05-12T06:35:18.658039Z","shell.execute_reply.started":"2024-05-12T06:35:18.648425Z","shell.execute_reply":"2024-05-12T06:35:18.657169Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def paraphrase(\n    text,\n    model,\n    tokenizer,\n    n=None,\n    max_length=\"auto\",\n    beams=5,\n):\n    texts = [text] if isinstance(text, str) else text\n    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True)[\"input_ids\"].to(\n        model.device\n    )\n\n    if max_length == \"auto\":\n        max_length = inputs.shape[1] + 10\n\n    result = model.generate(\n        inputs,\n        num_return_sequences=n or 1,\n        do_sample=False,\n        temperature=1.0,\n        repetition_penalty=10.0,\n        max_length=max_length,\n        min_length=int(0.5 * max_length),\n        num_beams=beams,\n        # forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang],\n    )\n    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n\n    if not n and isinstance(text, str):\n        return texts[0]\n    return texts[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.659255Z","iopub.execute_input":"2024-05-12T06:35:18.659811Z","iopub.status.idle":"2024-05-12T06:35:18.672947Z","shell.execute_reply.started":"2024-05-12T06:35:18.659779Z","shell.execute_reply":"2024-05-12T06:35:18.672183Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:18.673921Z","iopub.execute_input":"2024-05-12T06:35:18.674186Z","iopub.status.idle":"2024-05-12T06:35:37.240773Z","shell.execute_reply.started":"2024-05-12T06:35:18.674158Z","shell.execute_reply":"2024-05-12T06:35:37.239841Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd5829eddf04e8496be98d9cec2a2f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"723537cf605d4df598f8be84fce7e7b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be767e7d9cc24ac881e36bc4756e8694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"193378ebc3ee41eda2fe783a95143e56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79be589727114156a3262054d52c4071"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee49f41e5244004b11433562d92976e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a30372512934636b0a27b29b1f60465"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(eng_df, random_state=42, test_size=0.05)\n\ntrain = pd.DataFrame(train)\nval = pd.DataFrame(val)\n\n# lang = train[train[\"lang\"] == \"zh\"].lang[0]\nlang = \"en\"\ntrainset = DetoxDataset(train, tokenizer, lang)\nvalset = DetoxDataset(val, tokenizer, lang)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:37.241943Z","iopub.execute_input":"2024-05-12T06:35:37.242279Z","iopub.status.idle":"2024-05-12T06:35:37.268069Z","shell.execute_reply.started":"2024-05-12T06:35:37.242254Z","shell.execute_reply":"2024-05-12T06:35:37.267261Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"model\",\n    do_train=True,\n    do_eval=True,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=5,  # 8 is too much\n    weight_decay=1e-5,\n    num_train_epochs=3, # use 3 or 5 epochs here\n    learning_rate=1e-5,\n    evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    save_total_limit=1,\n    logging_steps=500,\n    gradient_accumulation_steps=1,\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:37.269232Z","iopub.execute_input":"2024-05-12T06:35:37.269540Z","iopub.status.idle":"2024-05-12T06:35:37.369581Z","shell.execute_reply.started":"2024-05-12T06:35:37.269504Z","shell.execute_reply":"2024-05-12T06:35:37.368781Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=trainset,\n    eval_dataset=valset,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:37.370708Z","iopub.execute_input":"2024-05-12T06:35:37.370997Z","iopub.status.idle":"2024-05-12T06:35:38.365074Z","shell.execute_reply.started":"2024-05-12T06:35:37.370962Z","shell.execute_reply":"2024-05-12T06:35:38.363704Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# cf252e122c0341df14b13db72773987d36dd67ec\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T06:35:38.366231Z","iopub.execute_input":"2024-05-12T06:35:38.366512Z","iopub.status.idle":"2024-05-12T08:39:24.254607Z","shell.execute_reply.started":"2024-05-12T06:35:38.366488Z","shell.execute_reply":"2024-05-12T08:39:24.253701Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240512_063616-jhtclnbj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/collaboration_team/huggingface/runs/jhtclnbj' target=\"_blank\">fresh-river-4</a></strong> to <a href='https://wandb.ai/collaboration_team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/collaboration_team/huggingface' target=\"_blank\">https://wandb.ai/collaboration_team/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/collaboration_team/huggingface/runs/jhtclnbj' target=\"_blank\">https://wandb.ai/collaboration_team/huggingface/runs/jhtclnbj</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8781' max='8781' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8781/8781 2:02:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>8.082100</td>\n      <td>0.150243</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.135300</td>\n      <td>0.094243</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.105600</td>\n      <td>0.089298</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.099400</td>\n      <td>0.086875</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.095700</td>\n      <td>0.085786</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.095100</td>\n      <td>0.084549</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.092300</td>\n      <td>0.083821</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.089900</td>\n      <td>0.083257</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.089900</td>\n      <td>0.082822</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.089400</td>\n      <td>0.082283</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.089000</td>\n      <td>0.082367</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.088200</td>\n      <td>0.082156</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.087600</td>\n      <td>0.081901</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.087600</td>\n      <td>0.081789</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.087400</td>\n      <td>0.081476</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.088000</td>\n      <td>0.081508</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.087100</td>\n      <td>0.081367</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8781, training_loss=0.5487573054775998, metrics={'train_runtime': 7425.5226, 'train_samples_per_second': 18.919, 'train_steps_per_second': 1.183, 'total_flos': 2.81822453991936e+16, 'train_loss': 0.5487573054775998, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/model/\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T08:39:24.256027Z","iopub.execute_input":"2024-05-12T08:39:24.256627Z","iopub.status.idle":"2024-05-12T08:39:25.628330Z","shell.execute_reply.started":"2024-05-12T08:39:24.256593Z","shell.execute_reply":"2024-05-12T08:39:25.627192Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!git clone https://huggingface.co/MOOsipenko/fine-tuned_T5_NLP_HW2","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:53:49.211163Z","iopub.execute_input":"2024-05-12T09:53:49.211888Z","iopub.status.idle":"2024-05-12T09:55:11.560585Z","shell.execute_reply.started":"2024-05-12T09:53:49.211856Z","shell.execute_reply":"2024-05-12T09:55:11.559384Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'fine-tuned_T5_NLP_HW2'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (16/16), done.\u001b[K\nremote: Compressing objects: 100% (16/16), done.\u001b[K\nremote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\nUnpacking objects: 100% (20/20), 7.40 KiB | 1.48 MiB/s, done.\nFiltering content: 100% (7/7), 3.69 GiB | 47.03 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/fine-tuned_T5_NLP_HW2/model\")\ntokenizer = T5Tokenizer.from_pretrained(\"/kaggle/working/fine-tuned_T5_NLP_HW2/model/checkpoint-8500\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:00:39.969788Z","iopub.execute_input":"2024-05-12T09:00:39.970164Z","iopub.status.idle":"2024-05-12T09:00:41.248269Z","shell.execute_reply.started":"2024-05-12T09:00:39.970135Z","shell.execute_reply":"2024-05-12T09:00:41.247133Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Predicting the English part of dev and test data","metadata":{}},{"cell_type":"code","source":"dev_indices_dict = {\"zh\": [0, 400], \"es\": [400, 800], \"ru\": [800, 1200], \"ar\": [1200, 1600],\n               \"hi\": [1600, 2000], \"uk\": [2000, 2400], \"de\": [2400, 2800], \"am\": [2800, 3200],\n               \"en\": [3200, 3600]}\n\ntest_indices_dict = {\"uk\": [0, 600], \"hi\": [600, 1200], \"zh\": [1200, 1800], \"ar\": [1800, 2400],\n               \"de\": [2400, 3000], \"en\": [3000, 3600], \"ru\": [3600, 4200], \"am\": [4200, 4800],\n               \"es\": [4800, 5400]}","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:00:49.901330Z","iopub.execute_input":"2024-05-12T09:00:49.901957Z","iopub.status.idle":"2024-05-12T09:00:49.910714Z","shell.execute_reply.started":"2024-05-12T09:00:49.901926Z","shell.execute_reply":"2024-05-12T09:00:49.909401Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"dev_df = pd.read_csv(\"/kaggle/input/public-hw2/inputs_multilingual.tsv\", sep=\"\\t\")\ntest_df = pd.read_csv(\"/kaggle/input/sample-submission/sample_submission_test.tsv\", sep=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:00:51.253854Z","iopub.execute_input":"2024-05-12T09:00:51.254689Z","iopub.status.idle":"2024-05-12T09:00:51.336494Z","shell.execute_reply.started":"2024-05-12T09:00:51.254658Z","shell.execute_reply":"2024-05-12T09:00:51.335289Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"dev_df_copy = dev_df.copy()\ntest_df_copy = test_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:00:51.773884Z","iopub.execute_input":"2024-05-12T09:00:51.774282Z","iopub.status.idle":"2024-05-12T09:00:51.781064Z","shell.execute_reply.started":"2024-05-12T09:00:51.774254Z","shell.execute_reply":"2024-05-12T09:00:51.779821Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# dev:\n\ndev_inputs = dev_df.iloc[3200:3600, 0].to_list()\ndev_preds = []\n\nfor text in tqdm(dev_inputs):\n    dev_preds.append(paraphrase(text, model, tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:00:53.141341Z","iopub.execute_input":"2024-05-12T09:00:53.141675Z","iopub.status.idle":"2024-05-12T09:10:50.720974Z","shell.execute_reply.started":"2024-05-12T09:00:53.141652Z","shell.execute_reply":"2024-05-12T09:10:50.719941Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"100%|██████████| 400/400 [09:57<00:00,  1.49s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"dev_df_copy.iloc[3200:3600, 1] = dev_preds","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:26:51.906101Z","iopub.execute_input":"2024-05-12T09:26:51.906494Z","iopub.status.idle":"2024-05-12T09:26:51.914551Z","shell.execute_reply.started":"2024-05-12T09:26:51.906467Z","shell.execute_reply":"2024-05-12T09:26:51.913259Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# test:\n\ntest_inputs = test_df.iloc[3000:3600, 0].to_list()\ntest_preds = []\n\nfor text in tqdm(test_inputs):\n    test_preds.append(paraphrase(text, model, tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:10:50.734760Z","iopub.execute_input":"2024-05-12T09:10:50.735054Z","iopub.status.idle":"2024-05-12T09:25:52.413061Z","shell.execute_reply.started":"2024-05-12T09:10:50.735024Z","shell.execute_reply":"2024-05-12T09:25:52.411686Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"100%|██████████| 600/600 [15:01<00:00,  1.50s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df_copy.iloc[3000:3600, 1] = test_preds","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:25:52.415408Z","iopub.execute_input":"2024-05-12T09:25:52.415805Z","iopub.status.idle":"2024-05-12T09:25:52.422750Z","shell.execute_reply.started":"2024-05-12T09:25:52.415772Z","shell.execute_reply":"2024-05-12T09:25:52.421719Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"test_df_copy.iloc[3000:3600, :]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:26:03.559480Z","iopub.execute_input":"2024-05-12T09:26:03.559884Z","iopub.status.idle":"2024-05-12T09:26:03.577572Z","shell.execute_reply.started":"2024-05-12T09:26:03.559843Z","shell.execute_reply":"2024-05-12T09:26:03.576460Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                         toxic_sentence  \\\n3000  mandated  and \" right fucking now \" would be g...   \n3001  &gt i wouldn 't care how ignorant you are in y...   \n3002                        6. are you fucking insane ?   \n3003   after all its hard to get a job if your stupid .   \n3004  after all most of these dorks are millionares ...   \n...                                                 ...   \n3595  what do you mean why don't you keep your nose ...   \n3596  Lets not edit user pages and look like a fucki...   \n3597  Stalking you little shit you need to stop foll...   \n3598  For fuck's sake When are they gonna send that ...   \n3599  He deserves every beating and rape he will be ...   \n\n                                       neutral_sentence lang  \n3000          mandated and \" right now \" would be good.   en  \n3001  &gt i wouldn 't care how ignorant you are in y...   en  \n3002                   6. are you insane? I don't know.   en  \n3003  After all its hard to get a job if you are not...   en  \n3004  after all most of these dorks are millionares ...   en  \n...                                                 ...  ...  \n3595  What do you mean why don't you keep your nose ...   en  \n3596  Let's not edit user pages and look like a moro...   en  \n3597  Stalking you little thing you need to stop fol...   en  \n3598  For fuck's sake, when are they gonna send that...   en  \n3599  He deserves every beating and rape he will be ...   en  \n\n[600 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_sentence</th>\n      <th>neutral_sentence</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3000</th>\n      <td>mandated  and \" right fucking now \" would be g...</td>\n      <td>mandated and \" right now \" would be good.</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3001</th>\n      <td>&amp;gt i wouldn 't care how ignorant you are in y...</td>\n      <td>&amp;gt i wouldn 't care how ignorant you are in y...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3002</th>\n      <td>6. are you fucking insane ?</td>\n      <td>6. are you insane? I don't know.</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3003</th>\n      <td>after all its hard to get a job if your stupid .</td>\n      <td>After all its hard to get a job if you are not...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3004</th>\n      <td>after all most of these dorks are millionares ...</td>\n      <td>after all most of these dorks are millionares ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3595</th>\n      <td>what do you mean why don't you keep your nose ...</td>\n      <td>What do you mean why don't you keep your nose ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3596</th>\n      <td>Lets not edit user pages and look like a fucki...</td>\n      <td>Let's not edit user pages and look like a moro...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3597</th>\n      <td>Stalking you little shit you need to stop foll...</td>\n      <td>Stalking you little thing you need to stop fol...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3598</th>\n      <td>For fuck's sake When are they gonna send that ...</td>\n      <td>For fuck's sake, when are they gonna send that...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3599</th>\n      <td>He deserves every beating and rape he will be ...</td>\n      <td>He deserves every beating and rape he will be ...</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>600 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Predicting the Russian part of dev and test data","metadata":{}},{"cell_type":"code","source":"def get_model(type: str) -> Tuple[PreTrainedModel, PreTrainedTokenizerFast]:\n    \"\"\"\n    Returns a pre-trained model and tokenizer based on the specified type.\n\n    Args:\n        type (str): The type of model to retrieve.\n        Valid options are \"translator\", \"en_detoxifier\", and \"ru_detoxifier\".\n\n    Returns:\n        (PreTrainedModel, PreTrainedTokenizer)\n    Raises:\n        ValueError: If an invalid type choice is provided.\n\n    Examples:\n        model, tokenizer = get_model(\"translator\")\n        model, tokenizer = get_model(\"en_detoxifier\")\n        model, tokenizer = get_model(\"ru_detoxifier\")\n    \"\"\"\n    device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n\n    model_types: Dict[str, Tuple[str, PreTrainedModel, PreTrainedTokenizerFast]] = {\n        \"translator\": (\n            \"facebook/nllb-200-distilled-600M\",\n            M2M100ForConditionalGeneration,\n            NllbTokenizerFast,\n        ),\n        \"en_detoxifier\": (\n            \"s-nlp/bart-base-detox\",\n            BartForConditionalGeneration,\n            BartTokenizerFast,\n        ),\n        \"ru_detoxifier\": (\n            \"s-nlp/ruT5-base-detox\",\n            T5ForConditionalGeneration,\n            T5TokenizerFast,\n        ),\n    }\n\n    if type not in model_types:\n        raise ValueError(\"Invalid type choice\")\n\n    model_name, ModelClass, TokenizerClass = model_types[type]\n\n    logging.info(f\"Loading {type} model: {model_name}\")\n\n    model = ModelClass.from_pretrained(model_name).eval().to(device)\n    tokenizer = TokenizerClass.from_pretrained(model_name)\n\n    return model, tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:26:56.488540Z","iopub.execute_input":"2024-05-12T09:26:56.489214Z","iopub.status.idle":"2024-05-12T09:26:56.498787Z","shell.execute_reply.started":"2024-05-12T09:26:56.489184Z","shell.execute_reply":"2024-05-12T09:26:56.497883Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def detoxify_batch(\n    texts: List[str],\n    model: Union[BartForConditionalGeneration, T5ForConditionalGeneration],\n    tokenizer: PreTrainedTokenizerFast,\n    batch_size: int = 32,\n) -> List[str]:\n    \"\"\"\n    Detoxify a batch of texts.\n\n    Args:\n        texts (List[str]): The list of texts to detoxify.\n        model (Union[BartForConditionalGeneration, T5ForConditionalGeneration]): The detoxification model.\n        tokenizer (PreTrainedTokenizerFast): The tokenizer for the detoxification model.\n        batch_size (int, optional): The batch size for detoxification. Defaults to 32.\n\n    Returns:\n        List[str]: The detoxified texts.\n    \"\"\"\n    detoxified = []\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Detoxifying\"):\n        batch = texts[i : i + batch_size]\n        batch_detoxified = model.generate(\n            **tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(\n                model.device\n            )\n        )\n        detoxified.extend(\n            tokenizer.decode(tokens, skip_special_tokens=True)\n            for tokens in batch_detoxified\n        )\n    return detoxified","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:26:56.950759Z","iopub.execute_input":"2024-05-12T09:26:56.951284Z","iopub.status.idle":"2024-05-12T09:26:56.961233Z","shell.execute_reply.started":"2024-05-12T09:26:56.951249Z","shell.execute_reply":"2024-05-12T09:26:56.960046Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = get_model(\"ru_detoxifier\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:26:57.824435Z","iopub.execute_input":"2024-05-12T09:26:57.825089Z","iopub.status.idle":"2024-05-12T09:27:50.997778Z","shell.execute_reply.started":"2024-05-12T09:26:57.825058Z","shell.execute_reply":"2024-05-12T09:27:50.996671Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"546665a604d14e87a38efc21bec5d6d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b768b5ffe464820ba45a1f24f5ebca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d51870d4c414de3bb6846c68396fd42"}},"metadata":{}}]},{"cell_type":"code","source":"# dev:\n\ndev_text = dev_df_copy.iloc[800:1200, 0].to_list()\ndetoxified_dev = detoxify_batch(dev_text, model, tokenizer, 16)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:27:50.999740Z","iopub.execute_input":"2024-05-12T09:27:51.000126Z","iopub.status.idle":"2024-05-12T09:28:00.854889Z","shell.execute_reply.started":"2024-05-12T09:27:51.000097Z","shell.execute_reply":"2024-05-12T09:28:00.850923Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"Detoxifying:   0%|          | 0/25 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nDetoxifying: 100%|██████████| 25/25 [00:09<00:00,  2.54it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"dev_df_copy.iloc[800:1200, 1] = detoxified_dev","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:00.856116Z","iopub.execute_input":"2024-05-12T09:28:00.856505Z","iopub.status.idle":"2024-05-12T09:28:00.863586Z","shell.execute_reply.started":"2024-05-12T09:28:00.856477Z","shell.execute_reply":"2024-05-12T09:28:00.862514Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#test:\n\ntest_text = test_df_copy.iloc[3600:4200, 0].to_list()\ndetoxified_test = detoxify_batch(test_text, model, tokenizer, 16)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:00.865834Z","iopub.execute_input":"2024-05-12T09:28:00.866386Z","iopub.status.idle":"2024-05-12T09:28:13.580065Z","shell.execute_reply.started":"2024-05-12T09:28:00.866361Z","shell.execute_reply":"2024-05-12T09:28:13.576539Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"Detoxifying:   0%|          | 0/38 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nDetoxifying: 100%|██████████| 38/38 [00:12<00:00,  2.99it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df_copy.iloc[3600:4200, 1] = detoxified_test","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:13.581422Z","iopub.execute_input":"2024-05-12T09:28:13.581760Z","iopub.status.idle":"2024-05-12T09:28:13.591769Z","shell.execute_reply.started":"2024-05-12T09:28:13.581730Z","shell.execute_reply":"2024-05-12T09:28:13.590861Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Predicting the rest languages","metadata":{}},{"cell_type":"code","source":"def detoxify(\n    text: str,\n    stopwords: List[str],\n    remove_all_terms: bool = False,\n    remove_no_terms: bool = False,\n) -> str:\n\n    if remove_no_terms:\n        return text\n    if remove_all_terms:\n        return \"\"\n    tokens = [\n        token\n        for token in text.replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\";\", \"\").replace(\"?\", \"\").replace(\"!\", \"\").split()\n        if not stopwords or token.lower().strip() not in stopwords\n    ]\n    return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:55.003922Z","iopub.execute_input":"2024-05-12T09:28:55.004778Z","iopub.status.idle":"2024-05-12T09:28:55.012484Z","shell.execute_reply.started":"2024-05-12T09:28:55.004750Z","shell.execute_reply":"2024-05-12T09:28:55.011417Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"dev_indices_dict = {\"zh\": [0, 400], \"es\": [400, 800], \"ru\": [800, 1200], \"ar\": [1200, 1600],\n               \"hi\": [1600, 2000], \"uk\": [2000, 2400], \"de\": [2400, 2800], \"am\": [2800, 3200],\n               \"en\": [3200, 3600]}","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:56.033096Z","iopub.execute_input":"2024-05-12T09:28:56.033740Z","iopub.status.idle":"2024-05-12T09:28:56.041798Z","shell.execute_reply.started":"2024-05-12T09:28:56.033712Z","shell.execute_reply":"2024-05-12T09:28:56.040631Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# dev:\n\ndev_zh_deleting = dev_df_copy.iloc[0:400, 0].to_list()\ndev_es_deleting = dev_df_copy.iloc[400:800, 0].to_list()\ndev_ar_deleting = dev_df_copy.iloc[1200:1600, 0].to_list()\ndev_hi_deleting = dev_df_copy.iloc[1600:2000, 0].to_list()\ndev_uk_deleting = dev_df_copy.iloc[2000:2400, 0].to_list()\ndev_de_deleting = dev_df_copy.iloc[2400:2800, 0].to_list()\ndev_am_deleting = dev_df_copy.iloc[2800:3200, 0].to_list()\n\ndev_list_of_lists = [dev_zh_deleting, dev_es_deleting, dev_ar_deleting, dev_hi_deleting, dev_uk_deleting, dev_de_deleting, dev_am_deleting]\ndev_language_list = [\"zh\", \"es\", \"ar\", \"hi\", \"uk\", \"de\", \"am\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:56.450980Z","iopub.execute_input":"2024-05-12T09:28:56.451854Z","iopub.status.idle":"2024-05-12T09:28:56.462676Z","shell.execute_reply.started":"2024-05-12T09:28:56.451825Z","shell.execute_reply":"2024-05-12T09:28:56.461548Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df_list = []\n\nfor k, i in tqdm(enumerate(dev_list_of_lists)):\n    \n    texts = []\n    stopwords = load_dataset(\"textdetox/multilingual_toxic_lexicon\")[dev_language_list[k]][\"text\"]\n    stopwords = set(stopwords)\n    \n    for j in i:\n        texts.append(detoxify(j, stopwords))\n        \n    df_list.append(pd.DataFrame({\"neutral\": texts}))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:28:57.027570Z","iopub.execute_input":"2024-05-12T09:28:57.027927Z","iopub.status.idle":"2024-05-12T09:31:21.735623Z","shell.execute_reply.started":"2024-05-12T09:28:57.027898Z","shell.execute_reply":"2024-05-12T09:31:21.734680Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e132ff171bb8495d85a62e2c48c01356"}},"metadata":{}},{"name":"stderr","text":"\nDownloading data:   0%|          | 0.00/3.04k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 3.04k/3.04k [00:00<00:00, 5.70kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/11.3k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 11.3k/11.3k [00:00<00:00, 23.6kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/1.88M [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 1.88M/1.88M [00:00<00:00, 3.84MB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/90.5k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 90.5k/90.5k [00:00<00:00, 181kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/33.9k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 33.9k/33.9k [00:00<00:00, 38.9kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/38.6k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 38.6k/38.6k [00:01<00:00, 35.1kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/4.58k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 4.58k/4.58k [00:00<00:00, 9.49kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/2.31k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 2.31k/2.31k [00:00<00:00, 4.32kB/s]\u001b[A\n\nDownloading data:   0%|          | 0.00/2.91k [00:00<?, ?B/s]\u001b[A\nDownloading data: 100%|██████████| 2.91k/2.91k [00:00<00:00, 5.66kB/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating am split:   0%|          | 0/245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9597f184888842e78f09948e9d4f596c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating es split:   0%|          | 0/1195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3559afb70d4f93966cd0f6a01a58a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating ru split:   0%|          | 0/140517 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a43b311cbf434cfbba804b274cb3af33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating uk split:   0%|          | 0/7356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283b971a017444cd923749831e568fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating en split:   0%|          | 0/3386 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0be65edf24d140bc85741befeeeecbb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating zh split:   0%|          | 0/3839 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"810a2e54dc6c4b51b8c6210acbefc4b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating ar split:   0%|          | 0/430 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d390cc0192346dc8027cc6880daaa64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating hi split:   0%|          | 0/133 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cadd435d1b84740adf7c8b6a1d8ac5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating de split:   0%|          | 0/247 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2053163a2f04413fb33ff413296ce51b"}},"metadata":{}},{"name":"stderr","text":"7it [02:24, 20.67s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"dev_df_copy.iloc[0:400, 1] = df_list[0].iloc[:, 0].to_list()\ndev_df_copy.iloc[400:800, 1] = df_list[1].iloc[:, 0].to_list()\ndev_df_copy.iloc[1200:1600, 1] = df_list[2].iloc[:, 0].to_list()\ndev_df_copy.iloc[1600:2000, 1] = df_list[3].iloc[:, 0].to_list()\ndev_df_copy.iloc[2000:2400, 1] = df_list[4].iloc[:, 0].to_list()\ndev_df_copy.iloc[2400:2800, 1] = df_list[5].iloc[:, 0].to_list()\ndev_df_copy.iloc[2800:3200, 1] = df_list[6].iloc[:, 0].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:31:21.737756Z","iopub.execute_input":"2024-05-12T09:31:21.738126Z","iopub.status.idle":"2024-05-12T09:31:21.754810Z","shell.execute_reply.started":"2024-05-12T09:31:21.738091Z","shell.execute_reply":"2024-05-12T09:31:21.753466Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"dev_df_copy = dev_df_copy.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:31:21.756653Z","iopub.execute_input":"2024-05-12T09:31:21.757045Z","iopub.status.idle":"2024-05-12T09:31:21.771005Z","shell.execute_reply.started":"2024-05-12T09:31:21.756984Z","shell.execute_reply":"2024-05-12T09:31:21.769938Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"dev_df_copy.to_csv(\"final_dev.tsv\", sep=\"\\t\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:31:21.774194Z","iopub.execute_input":"2024-05-12T09:31:21.774573Z","iopub.status.idle":"2024-05-12T09:31:21.825470Z","shell.execute_reply.started":"2024-05-12T09:31:21.774538Z","shell.execute_reply":"2024-05-12T09:31:21.824197Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# test:\n\ntest_uk_deleting = test_df_copy.iloc[0:600, 0].to_list()\ntest_hi_deleting = test_df_copy.iloc[600:1200, 0].to_list()\ntest_zh_deleting = test_df_copy.iloc[1200:1800, 0].to_list()\ntest_ar_deleting = test_df_copy.iloc[1800:2400, 0].to_list()\ntest_de_deleting = test_df_copy.iloc[2400:3000, 0].to_list()\ntest_am_deleting = test_df_copy.iloc[4200:4800, 0].to_list()\ntest_es_deleting = test_df_copy.iloc[4800:5400, 0].to_list()\n\ntest_list_of_lists = [test_uk_deleting, test_hi_deleting, test_zh_deleting, test_ar_deleting, test_de_deleting, test_am_deleting, test_es_deleting]\ndev_language_list = [\"uk\", \"hi\", \"zh\", \"ar\", \"de\", \"am\", \"es\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:31:21.826725Z","iopub.execute_input":"2024-05-12T09:31:21.827529Z","iopub.status.idle":"2024-05-12T09:31:21.838636Z","shell.execute_reply.started":"2024-05-12T09:31:21.827495Z","shell.execute_reply":"2024-05-12T09:31:21.837564Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"df_list = []\n\nfor k, i in tqdm(enumerate(test_list_of_lists)):\n    \n    texts = []\n    stopwords = load_dataset(\"textdetox/multilingual_toxic_lexicon\")[dev_language_list[k]][\"text\"]\n    stopwords = set(stopwords)\n    \n    for j in i:\n        texts.append(detoxify(j, stopwords))\n        \n    df_list.append(pd.DataFrame({\"neutral\": texts}))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:31:21.840038Z","iopub.execute_input":"2024-05-12T09:31:21.840373Z","iopub.status.idle":"2024-05-12T09:33:31.361226Z","shell.execute_reply.started":"2024-05-12T09:31:21.840344Z","shell.execute_reply":"2024-05-12T09:33:31.360266Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"7it [02:09, 18.50s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df_copy.iloc[0:600, 1] = df_list[0].iloc[:, 0].to_list()\ntest_df_copy.iloc[600:1200, 1] = df_list[1].iloc[:, 0].to_list()\ntest_df_copy.iloc[1200:1800, 1] = df_list[2].iloc[:, 0].to_list()\ntest_df_copy.iloc[1800:2400, 1] = df_list[3].iloc[:, 0].to_list()\ntest_df_copy.iloc[2400:3000, 1] = df_list[4].iloc[:, 0].to_list()\ntest_df_copy.iloc[4200:4800, 1] = df_list[5].iloc[:, 0].to_list()\ntest_df_copy.iloc[4800:5400, 1] = df_list[6].iloc[:, 0].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:33:31.362597Z","iopub.execute_input":"2024-05-12T09:33:31.363419Z","iopub.status.idle":"2024-05-12T09:33:31.373519Z","shell.execute_reply.started":"2024-05-12T09:33:31.363384Z","shell.execute_reply":"2024-05-12T09:33:31.372649Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"test_df_copy = test_df_copy.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:33:31.374600Z","iopub.execute_input":"2024-05-12T09:33:31.374832Z","iopub.status.idle":"2024-05-12T09:33:31.385892Z","shell.execute_reply.started":"2024-05-12T09:33:31.374812Z","shell.execute_reply":"2024-05-12T09:33:31.385091Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"test_df_copy.to_csv(\"final_test.tsv\", sep=\"\\t\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T09:33:31.386890Z","iopub.execute_input":"2024-05-12T09:33:31.387621Z","iopub.status.idle":"2024-05-12T09:33:31.446848Z","shell.execute_reply.started":"2024-05-12T09:33:31.387596Z","shell.execute_reply":"2024-05-12T09:33:31.445972Z"},"trusted":true},"execution_count":53,"outputs":[]}]}